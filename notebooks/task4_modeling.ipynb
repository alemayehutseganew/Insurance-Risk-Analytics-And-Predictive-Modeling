{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ad0422",
   "metadata": {},
   "source": [
    "# Task 4 â€” Severity Modeling Comparison\n",
    "\n",
    "Evaluate baseline and ensemble regressors using the shared preprocessing and evaluation utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ae95903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import src.modeling\n",
    "importlib.reload(src.modeling)\n",
    "\n",
    "from src.modeling import (\n",
    "    load_data,\n",
    "    preprocess_for_severity,\n",
    "    preprocess_for_premium,\n",
    "    preprocess_for_claim_probability,\n",
    "    train_test_split_df,\n",
    "    build_severity_preprocessor,\n",
    "    evaluate_regression_models,\n",
    "    evaluate_classification_models,\n",
    "    build_default_severity_models,\n",
    "    build_default_premium_models,\n",
    "    build_default_classification_models,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fa02d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel check\n"
     ]
    }
   ],
   "source": [
    "print('kernel check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a884860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexo\\Desktop\\File\\10Academy\\week3\\github\\Insurance-Risk-Analytics-And-Predictive-Modeling\\src\\modeling.py:104: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  - pd.to_datetime(engineered.get('VehicleIntroDate', pd.NaT), errors='coerce').dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (500, 21), Test shape: (126, 21)\n"
     ]
    }
   ],
   "source": [
    "df = load_data(nrows=200000)\n",
    "\n",
    "X, y = preprocess_for_severity(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_df(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "preprocessor = build_severity_preprocessor(X_train)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f5bf697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>23026.73</td>\n",
       "      <td>-0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>28190.25</td>\n",
       "      <td>-0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>34322.84</td>\n",
       "      <td>-1.329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model      rmse      r2\n",
       "0       LinearRegression  23026.73  -0.048\n",
       "1  RandomForestRegressor  28190.25  -0.571\n",
       "2           XGBRegressor  34322.84  -1.329"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = build_default_severity_models()\n",
    "\n",
    "results_df, trained_models = evaluate_regression_models(\n",
    "\n",
    "    models,\n",
    "\n",
    "    X_train,\n",
    "\n",
    "    y_train,\n",
    "\n",
    "    X_test,\n",
    "\n",
    "    y_test,\n",
    "\n",
    "    preprocessor,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "formatted_results = results_df.copy()\n",
    "\n",
    "if not formatted_results.empty:\n",
    "\n",
    "    formatted_results[\"rmse\"] = formatted_results[\"rmse\"].map(\"{:.2f}\".format)\n",
    "\n",
    "    formatted_results[\"r2\"] = formatted_results[\"r2\"].map(\"{:.3f}\".format)\n",
    "\n",
    "formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ab0e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LinearRegression\n"
     ]
    }
   ],
   "source": [
    "if not results_df.empty:\n",
    "    best_model_name = results_df.iloc[0][\"model\"]\n",
    "    best_pipeline = trained_models[best_model_name]\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    residuals = y_test - y_pred\n",
    "    diagnostics = pd.DataFrame(\n",
    "        {\n",
    "            \"metric\": [\"rmse\", \"mae\", \"r2\"],\n",
    "            \"value\": [\n",
    "                results_df.iloc[0][\"rmse\"],\n",
    "                mae,\n",
    "                results_df.iloc[0][\"r2\"],\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    diagnostics\n",
    "else:\n",
    "    print(\"No models evaluated. Check model dependencies (e.g., xgboost).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b48aa751",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not results_df.empty:\n",
    "    best_model_name = results_df.iloc[0][\"model\"]\n",
    "    best_pipeline = trained_models[best_model_name]\n",
    "    importance = permutation_importance(\n",
    "        best_pipeline,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        n_repeats=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    importance_df = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": X_test.columns,\n",
    "                \"importance_mean\": importance.importances_mean,\n",
    "                \"importance_std\": importance.importances_std,\n",
    "            }\n",
    "        )\n",
    "        .sort_values(\"importance_mean\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    importance_df.head(15)\n",
    "else:\n",
    "    print(\"Permutation importance skipped because no models were trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cda9bc",
   "metadata": {},
   "source": [
    "## Premium Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e32686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexo\\Desktop\\File\\10Academy\\week3\\github\\Insurance-Risk-Analytics-And-Predictive-Modeling\\src\\modeling.py:104: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  - pd.to_datetime(engineered.get('VehicleIntroDate', pd.NaT), errors='coerce').dt.year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>54.64</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model   rmse     r2\n",
       "1  RandomForestRegressor  11.33  0.997\n",
       "2           XGBRegressor  17.15  0.994\n",
       "0       LinearRegression  54.64  0.942"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xp, yp = preprocess_for_premium(df)\n",
    "\n",
    "Xp_train, Xp_test, yp_train, yp_test = train_test_split_df(\n",
    "    Xp,\n",
    "    yp,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "premium_preprocessor = build_severity_preprocessor(Xp_train)\n",
    "premium_models = build_default_premium_models()\n",
    "premium_results_df, premium_trained_models = evaluate_regression_models(\n",
    "    premium_models,\n",
    "    Xp_train,\n",
    "    yp_train,\n",
    "    Xp_test,\n",
    "    yp_test,\n",
    "    premium_preprocessor,\n",
    ")\n",
    "\n",
    "premium_formatted = premium_results_df.copy()\n",
    "if not premium_formatted.empty:\n",
    "    premium_formatted[\"rmse\"] = premium_formatted[\"rmse\"].map(\"{:.2f}\".format)\n",
    "    premium_formatted[\"r2\"] = premium_formatted[\"r2\"].map(\"{:.3f}\".format)\n",
    "premium_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61fdc572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best premium model: RandomForestRegressor\n"
     ]
    }
   ],
   "source": [
    "if not premium_results_df.empty:\n",
    "    best_premium_model = premium_results_df.iloc[0][\"model\"]\n",
    "    best_premium_pipeline = premium_trained_models[best_premium_model]\n",
    "    premium_preds = best_premium_pipeline.predict(Xp_test)\n",
    "    premium_mae = mean_absolute_error(yp_test, premium_preds)\n",
    "    premium_diagnostics = pd.DataFrame(\n",
    "        {\n",
    "            \"metric\": [\"rmse\", \"mae\", \"r2\"],\n",
    "            \"value\": [\n",
    "                premium_results_df.iloc[0][\"rmse\"],\n",
    "                premium_mae,\n",
    "                premium_results_df.iloc[0][\"r2\"],\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    print(f\"Best premium model: {best_premium_model}\")\n",
    "    premium_diagnostics\n",
    "else:\n",
    "    print(\"No premium models evaluated. Check inputs or dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5442607",
   "metadata": {},
   "source": [
    "## Claim Probability Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0254866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexo\\Desktop\\File\\10Academy\\week3\\github\\Insurance-Risk-Analytics-And-Predictive-Modeling\\src\\modeling.py:104: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  - pd.to_datetime(engineered.get('VehicleIntroDate', pd.NaT), errors='coerce').dt.year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model accuracy precision recall     f1\n",
       "1  RandomForestClassifier    0.989     0.022  0.056  0.031\n",
       "0      LogisticRegression    0.780     0.013  0.912  0.025\n",
       "2           XGBClassifier    0.997     0.000  0.000  0.000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc, yc = preprocess_for_claim_probability(df)\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split_df(\n",
    "    Xc,\n",
    "    yc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=yc,\n",
    ")\n",
    "\n",
    "classification_preprocessor = build_severity_preprocessor(Xc_train)\n",
    "classification_models = build_default_classification_models()\n",
    "classification_results_df, classification_trained_models = evaluate_classification_models(\n",
    "    classification_models,\n",
    "    Xc_train,\n",
    "    yc_train,\n",
    "    Xc_test,\n",
    "    yc_test,\n",
    "    classification_preprocessor,\n",
    ")\n",
    "\n",
    "classification_formatted = classification_results_df.copy()\n",
    "if not classification_formatted.empty:\n",
    "    metric_formats = {\n",
    "        \"accuracy\": \"{:.3f}\",\n",
    "        \"precision\": \"{:.3f}\",\n",
    "        \"recall\": \"{:.3f}\",\n",
    "        \"f1\": \"{:.3f}\",\n",
    "    }\n",
    "    for metric, format_str in metric_formats.items():\n",
    "        classification_formatted[metric] = classification_formatted[metric].map(format_str.format)\n",
    "classification_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf8fe3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best classifier: RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "if not classification_results_df.empty:\n",
    "    best_classifier_name = classification_results_df.iloc[0][\"model\"]\n",
    "    best_classifier_pipeline = classification_trained_models[best_classifier_name]\n",
    "    best_classifier_metrics = (\n",
    "        classification_results_df.iloc[0][[\"accuracy\", \"precision\", \"recall\", \"f1\"]]\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"metric\", 0: \"value\"})\n",
    "    )\n",
    "    print(f\"Best classifier: {best_classifier_name}\")\n",
    "    best_classifier_metrics\n",
    "else:\n",
    "    print(\"No classification models evaluated. Check inputs or dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab874c",
   "metadata": {},
   "source": [
    "## Model Interpretability with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecd2cbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features by SHAP Importance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_abs_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat__Model_QUANTUM 2.7 SESFIKILE 16s</td>\n",
       "      <td>16753.495663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__kilowatts</td>\n",
       "      <td>14864.731561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num__VehicleIntroAge</td>\n",
       "      <td>11469.062831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat__Model_QUANTUM 2.7 SESFIKILE 15s</td>\n",
       "      <td>10435.629706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__CalculatedPremiumPerTerm</td>\n",
       "      <td>8338.591309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num__TotalPremium</td>\n",
       "      <td>5851.157664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat__Model_QUANTUM 2.7 SESFIKILE 14s</td>\n",
       "      <td>5339.394935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat__Model_HiACE SUPER 16 F/Lift</td>\n",
       "      <td>5174.410550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cat__CoverType_Windscreen</td>\n",
       "      <td>4568.256582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num__SumInsured</td>\n",
       "      <td>4334.405740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature  mean_abs_shap\n",
       "0  cat__Model_QUANTUM 2.7 SESFIKILE 16s   16753.495663\n",
       "1                        num__kilowatts   14864.731561\n",
       "2                  num__VehicleIntroAge   11469.062831\n",
       "3  cat__Model_QUANTUM 2.7 SESFIKILE 15s   10435.629706\n",
       "4         num__CalculatedPremiumPerTerm    8338.591309\n",
       "5                     num__TotalPremium    5851.157664\n",
       "6  cat__Model_QUANTUM 2.7 SESFIKILE 14s    5339.394935\n",
       "7      cat__Model_HiACE SUPER 16 F/Lift    5174.410550\n",
       "8             cat__CoverType_Windscreen    4568.256582\n",
       "9                       num__SumInsured    4334.405740"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "if not results_df.empty:\n",
    "    # Limit background and evaluation sets for performance\n",
    "    background = X_train.sample(min(500, len(X_train)), random_state=42)\n",
    "    evaluation_data = X_test.head(200)\n",
    "\n",
    "    # Transform data using the pipeline's preprocessor\n",
    "    preprocessor = best_pipeline.named_steps[\"preprocessor\"]\n",
    "    model = best_pipeline.named_steps[\"model\"]\n",
    "    \n",
    "    X_bg_transformed = preprocessor.transform(background)\n",
    "    X_eval_transformed = preprocessor.transform(evaluation_data)\n",
    "    \n",
    "    # Get feature names\n",
    "    try:\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "    except AttributeError:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(X_bg_transformed.shape[1])]\n",
    "\n",
    "    # Use the transformed data to explain the inner model\n",
    "    explainer = shap.Explainer(model, X_bg_transformed)\n",
    "    shap_values = explainer(X_eval_transformed)\n",
    "    \n",
    "    # Handle Explanation object vs list (for classification) vs array\n",
    "    if hasattr(shap_values, 'values'):\n",
    "        vals = shap_values.values\n",
    "    else:\n",
    "        vals = shap_values\n",
    "\n",
    "    # If classification (list of arrays or array with extra dim), take positive class\n",
    "    if isinstance(vals, list):\n",
    "        vals = vals[1]\n",
    "    elif vals.ndim > 2:\n",
    "        vals = vals[:, :, 1] # Assuming binary classification, index 1 is positive\n",
    "\n",
    "    shap_importance = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": feature_names,\n",
    "                \"mean_abs_shap\": np.abs(vals).mean(0),\n",
    "            }\n",
    "        )\n",
    "        .sort_values(\"mean_abs_shap\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"Top 10 Features by SHAP Importance:\")\n",
    "    display(shap_importance.head(10))\n",
    "else:\n",
    "    print(\"SHAP skipped because severity models are unavailable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
